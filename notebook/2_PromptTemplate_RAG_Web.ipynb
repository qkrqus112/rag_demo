{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG 실습: Web 데이터 로딩 & PromptTemplate 활용\n",
    "\n",
    "이 노트북에서는 포켓몬스터 나무위키 페이지에서 데이터를 로드하여 RAG(검색 증강 생성) 실습을 진행합니다.  \n",
    "PromptTemplate을 활용한 다양한 프롬프트 구성 방법도 함께 다룹니다.\n",
    "\n",
    "---\n",
    "**실습 목표**\n",
    "- 웹에서 문서를 로드하고, 텍스트를 청크로 분할\n",
    "- 임베딩 및 벡터 DB 구축\n",
    "- 검색 기반 답변 생성(RAG) 체인 구성\n",
    "- PromptTemplate과 LangChain Hub 프롬프트 활용법 이해\n",
    "- RunnablePassthrough 등 체인 유틸리티 활용법 익히기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 변수 불러오기\n",
    "\n",
    "- OpenAI API 키 등 민감 정보는 .env 파일에 저장합니다.\n",
    "- dotenv를 통해 환경 변수를 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 웹 문서 로딩 및 텍스트 분할\n",
    "\n",
    "- WebBaseLoader로 나무위키 포켓몬 타입 문서를 불러옵니다.\n",
    "- RecursiveCharacterTextSplitter로 문서를 일정 길이의 청크로 분할합니다.\n",
    "- 분할된 청크는 이후 임베딩 및 검색에 활용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "url = \"https://namu.wiki/w/%ED%8F%AC%EC%BC%93%EB%AA%AC%EC%8A%A4%ED%84%B0/%ED%83%80%EC%9E%85\"\n",
    "loader = WebBaseLoader(url)\n",
    "docs = loader.load()\n",
    "print(f\"Loaded {len(docs)} document(s) from {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "chunks = text_splitter.split_documents(docs)\n",
    "print(f\"Split into {len(chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 임베딩 및 Chroma DB 구축\n",
    "\n",
    "- 분할된 청크 데이터를 임베딩(벡터화)합니다.\n",
    "- Chroma 벡터 데이터베이스에 저장하여 검색이 가능하도록 만듭니다.\n",
    "- OpenAIEmbeddings를 사용하며, persist_directory로 DB를 파일로 저장할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embedding = OpenAIEmbeddings(model='text-embedding-3-large')\n",
    "\n",
    "database = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedding,\n",
    "    collection_name='pokemon',\n",
    "    persist_directory=\"../chroma\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retriever 준비\n",
    "# as_retriever()로 벡터 DB에서 유사한 문서를 검색하는 객체를 생성합니다.\n",
    "retriever = database.as_retriever(search_kwargs={'k': 2})\n",
    "\n",
    "question = \"포켓몬 타입 상성에 대해 알려줘.\"\n",
    "retrieved_docs = retriever.invoke(question)\n",
    "for i, doc in enumerate(retrieved_docs, 1):\n",
    "    print(f\"[{i}] {doc.page_content[:200]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. PromptTemplate을 활용한 답변 생성\n",
    "\n",
    "- PromptTemplate을 사용하면 context(검색 결과)와 question(질문)을 조합해 원하는 형태의 프롬프트를 쉽게 만들 수 있습니다.\n",
    "- 아래 예시는 context와 question을 받아 이모티콘을 활용해 친근하게 답변하도록 LLM에 요청합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o', temperature=0)\n",
    "\n",
    "rag_prompt_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    아래는 포켓몬 타입에 대한 정보입니다.\n",
    "    이모티콘을 사용해서 친근하게 답변하세요.\n",
    "    {context}\n",
    "\n",
    "    질문: {question}\n",
    "    답변:\n",
    "    \"\"\",\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "prompt = rag_prompt_template.format(context=context, question=question)\n",
    "response = llm.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LangChain Hub의 프롬프트 활용\n",
    "\n",
    "- LangChain Hub에는 다양한 RAG(검색 증강 생성) 시나리오에 맞게 설계된 표준 프롬프트가 저장되어 있습니다.\n",
    "- `\"rlm/rag-prompt\"`는 context(검색 결과)와 question(질문)을 받아, LLM이 참고 문맥을 활용해 답변하도록 유도하는 구조의 프롬프트입니다.\n",
    "- 직접 프롬프트를 작성하지 않아도 검증된 템플릿을 바로 사용할 수 있습니다.\n",
    "- hub.pull()로 프롬프트를 불러와 chain에 바로 연결할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "hub_prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "rag_chain = hub_prompt | llm\n",
    "result = rag_chain.invoke({\"context\": context, \"question\": question})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. RunnablePassthrough로 Chain 구성\n",
    "\n",
    "- RunnablePassthrough는 입력값을 가공하지 않고 그대로 다음 단계로 전달할 때 사용하는 LangChain 유틸리티입니다.\n",
    "- 여러 입력값 중 일부만 그대로 다음 runnable에 넘기고 싶을 때 활용할 수 있습니다.\n",
    "- 아래 예시는 context는 retriever에서, question은 그대로 넘겨서 프롬프트에 전달합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | hub_prompt\n",
    "    | llm\n",
    ")\n",
    "result = rag_chain.invoke(question)\n",
    "print(result.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
